








import pandas as pd


# store the .csv in sp variable
sp = pd.read_csv("data/StudentsPerformance.csv")


sp.head()





sp["parental level of education"].unique()





sp.tail()





sp.describe()





sp.describe(include="all")





sp.columns





sp.dtypes








sp.count()


sp.info()





sp.isnull().sum()








import matplotlib.pyplot as plt
import seaborn as sns


sns.catplot(data=sp)





sns.catplot(data=sp, x="reading score", y="parental level of education")





sns.catplot(data=sp, kind="box")





sns.catplot(data=sp, x="math score", y="gender", kind="box")





sns.catplot(data=sp, x="math score", y="test preparation course", kind="box") #...





sns.catplot(data=sp, x="math score", y="parental level of education", kind="box") #...





sns.catplot(data=sp, x="math score", y="parental level of education", hue="gender", kind="box")





sns.catplot(data=sp, x="reading score", y="parental level of education", hue="gender", kind="box") #..





sns.catplot(data=sp, x="writing score", y="parental level of education", hue="gender", kind="box") #..





sns.catplot(data=sp, x="math score", y="parental level of education", hue="race/ethnicity", kind="box") #..





sns.catplot(data=sp, x="math score", y="parental level of education", hue="gender", kind="swarm")














sp['AVG'] = ((sp['math score'] + sp['writing score'] + sp['reading score']) / 3).round(decimals=2)





sp.head()


def categorize_score(avg_score):
    if avg_score <= 40:
        return 'LOW'
    elif 41 <= avg_score <= 50:
        return 'BELOW MEDIUM'
    elif 51 <= avg_score <= 75:
        return 'MEDIUM'
    elif 76 <= avg_score <= 85:
        return 'ABOVE MEDIUM'
    elif 86 <= avg_score <= 100:
        return 'HIGH'
    else:
        return 'Out of range'





sp['AVG Category'] = sp['AVG'].apply(categorize_score)





sp.head()


# Defining bins for categorizing average scores
bins = [0, 40, 50, 75, 85, 100]
labels = ['LOW', 'BELOW MEDIUM', 'MEDIUM', 'ABOVE MEDIUM', 'HIGH']

# new column 'AVG Category' based on bins
sp['AVG Category'] = pd.cut(sp['AVG'], bins=bins, labels=labels, include_lowest=True)

# Count the number of students in each category
category_counts = sp['AVG Category'].value_counts()

plt.bar(category_counts.index, category_counts.values, color='skyblue')
plt.xlabel('Average Score Category')
plt.ylabel('Number of Students')
plt.title('Distribution of Average Score Categories')
plt.xticks(rotation=40)
plt.show()





sp["race/ethnicity"].unique()


sp_encoded = pd.get_dummies(sp, columns=['parental level of education', 'lunch', 'race/ethnicity'])
sp_encoded.head()











sp[['math score', 'writing score', 'reading score']].describe()





race_counts = sp['race/ethnicity'].value_counts()
race_counts


plt.figure(figsize=(8, 5))
race_counts.plot(kind='bar', color='skyblue')
plt.xlabel('Race/Ethnicity')
plt.ylabel('Frequency')
plt.title('Frequency of Race/Ethnicity')
plt.xticks(rotation=45)
plt.show()


df_pivot = sp.pivot_table(index="race/ethnicity", columns="gender", aggfunc="size")
df_pivot = df_pivot.sort_values(by="female", ascending=False)
df_pivot.plot(kind="bar")

plt.xlabel("Ethnicity")
plt.ylabel("Count")
plt.title("Frequency of race/ethnicity + genders within")
plt.xticks(rotation=45)
plt.show()



lunch_counts = sp['lunch'].value_counts()
lunch_counts


plt.figure(figsize=(8, 5))
lunch_counts.plot(kind='bar', color='skyblue')
plt.xlabel('Lunch')
plt.ylabel('Frequency')
plt.title('Frequency of different lunch types')
plt.xticks(rotation=0)
plt.show()


# ploe = parental lvl of edu
ploe = sp['parental level of education'].value_counts() 
ploe


plt.figure(figsize=(8, 5))
ploe.plot(kind='bar', color='skyblue')
plt.xlabel('Parental level of education')
plt.ylabel('Frequency')
plt.title('Frequency of Parental level of education')
plt.xticks(rotation=45)
plt.show()


gender_count = sp['gender'].value_counts()
gender_count


plt.figure(figsize=(8, 5))
gender_count.plot(kind='bar', color='skyblue')
plt.xlabel('Genders')
plt.ylabel('Frequency')
plt.title('Frequency of different genders')
plt.xticks(rotation=0)
plt.show()


test_prep_count = sp['test preparation course'].value_counts()
test_prep_count


plt.figure(figsize=(8, 5))
test_prep_count.plot(kind='bar', color='skyblue')
plt.xlabel('Test preparation course')
plt.ylabel('Frequency')
plt.title('Frequency of students taking the test preparation course')
plt.xticks(rotation=0)
plt.show()











new_read = pd.read_csv("data/StudentsPerformance.csv")
# Select subset of columns
# Group by 'gender' and 'test preperation course' and calculate the mean of numeric columns
mean_values = new_read.groupby(['gender', 'test preparation course'])[['math score']].mean()
print(mean_values)





# Group by 'gender' and calculate the mean of numeric columns
mean_values = new_read.groupby(['gender', 'race/ethnicity', 'parental level of education', 'test preparation course', 'lunch'])[['math score', 'reading score', 'writing score']].mean()

#Reset index to make the grouped columns normal columns
mean_values.reset_index(inplace=True)

# Save the mean_values DataFrame to a CSV file
mean_values.to_csv("data/mean_math_scores.csv", index=False)

print("Mean values saved to data/mean_scores.csv")








# Create a pairplot to visualize the pairwise relationships in the dataset.
sns.pairplot(sp, hue='gender', markers=['o', 's'], diag_kind='kde', corner=True)
plt.suptitle("Pairplot of Variables", y=1.02)
plt.show()








import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, root_mean_squared_error

# student performance data set
sp_ds = pd.read_csv("data/StudentsPerformance.csv")

# Encode categorical variables
data_encoded = pd.get_dummies(sp_ds, columns=['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course'])

# Extract features and target variable
X = data_encoded.drop(['math score', 'reading score', 'writing score'], axis=1)  # Features
y = data_encoded['math score']  # Target variable to predict

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)

print('R^2 score: ', r2_score(y_test, y_pred))
print('RMSE: ', root_mean_squared_error(y_test, y_pred))







