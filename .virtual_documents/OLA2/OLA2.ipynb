





import pandas as pd

cities = ['2800', '2820', '2830', '2840', '2850', '2900', '2920', '2930', '2942', '2950','3000','3460']
dataframes = []

for city in cities:
    filename = f'./house_data/house_data_{city}.csv'
    df = pd.read_csv(filename)
    df['City'] = city
    dataframes.append(df)

housing = pd.concat(dataframes, ignore_index=True)
housing["Type"].unique()

housing = housing.rename(columns={'X': 'longitude'})
housing = housing.rename(columns={'Y': 'latitude'})
housing = housing.drop(columns=["Url"])
housing.head()


housing.count()


housing["Type"].value_counts()


landeejendom_df = housing[housing['Type'] == 'Landejendom']
landeejendom_df





housing = housing[housing['Type'] != 'Landejendom']
housing["Type"].value_counts()





housing["Energy class"].value_counts()


housing.describe()


sorted_df = housing.sort_values(by='Price', ascending=False)
sorted_df.head()





housing.columns


housing.dtypes


housing.isnull().sum()


# Alternative for the two calls above
housing.info()





import matplotlib.pyplot as plt
import seaborn as sns

sns.catplot(data=housing, kind="box")


housing.hist(bins=50, figsize=(20, 15))
plt.show()


sns.catplot(data=housing, x="Price", kind="box")


sns.catplot(data=housing, x="Size", kind="box")








housing.plot(kind="scatter", x="latitude", y="longitude")





housing.plot(kind="scatter", x="latitude", y="longitude", alpha=0.1)





housing.plot(kind="scatter", x="latitude", y="longitude", alpha=0.4, s=housing["Price"]/1000000, label="Price", figsize=(10,7), c="Squaremeter price", cmap=plt.get_cmap("jet"), colorbar=True,)
plt.legend()








housing.head()





# Rows containing missing values are dropped
housing.dropna(inplace=True)





from sklearn.preprocessing import StandardScaler

# data preparation using one-hot-encoding on categorical values
housing = pd.get_dummies(housing, columns=['City', 'Energy class', 'Type'])


# scaling the Size and the Price
#scaler = StandardScaler()
#housing['Size'] = scaler.fit_transform(housing[['Size']]) # keep in mind - maybe remove
#housing['Price'] = scaler.fit_transform(housing[['Price']]) # keep in mind - maybe remove


housing.head()





# Splitting data in features (X) and target (y)
X = housing.drop(['Price','Squaremeter price', 'Address'], axis=1)
y = housing['Price']





from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)





from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error, f1_score

linear_model = LinearRegression()
linear_model.fit(X_train, y_train)





# Making predictions on the test set
predictions = linear_model.predict(X_test)

print('R^2 score: ', r2_score(y_test, predictions))
mse = mean_squared_error(y_test, predictions)
rmse = mse**0.5
print(f"Root Mean Squared Error (RMSE): {rmse}")








from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)


# Making predictions on the test set
y_pred = rf_model.predict(X_test)

r2 = r2_score(y_test, y_pred)
print(f"R2-score {r2}")

mse = mean_squared_error(y_test, y_pred)
rmse = mse**0.5
print(f"Root Mean Squared Error (RMSE): {rmse}")





from sklearn.preprocessing import LabelEncoder

cities = ['2800', '2820', '2830', '2840', '2850', '2900', '2920', '2930', '2942', '2950', '3000', '3460']
dataframes = []

for city in cities:
    filename = f'./house_data/house_data_{city}.csv'
    df = pd.read_csv(filename)
    df["City"] = int(city)
    dataframes.append(df)
data = pd.concat(dataframes, ignore_index=True)

data.head(5)


data.dropna(inplace=True) # drop null values if they exist
data.drop(columns=['Url'], inplace=True) # remove the url column


features = ['X', 'Y', 'Size', 'Type', 'Energy class', 'City'] # our features we want the model to train on
target = 'Price' # the feature that we want the model to predict on


# data["Energy class"].unique() # used to try and do label encoding with our own ordering


# data.count()


# adding these lines of code will remove the 2 rows with type Landeejendom, resulting in a lower R2 score.. not sure why that is..
#data = data[data['Type'] != 'Landejendom']
#data.count()


# data["Type"].unique() # used to try and do label encoding with our own ordering


# defining an order for energy classes and type:
# energy_class_order = ["A2020", "A2015", "A2010", "B", "C", "D", "E", "F", "G"]
# type_order = ["Villa", "Villalejlighed", "Ejerlejlighed", "RÃ¦kkehus"]


label_encoders = {}
for feature in features:
    if data[feature].dtype == 'object':
        label_encoders[feature] = LabelEncoder()
        data[feature] = label_encoders[feature].fit_transform(data[feature])
print(label_encoders)


X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], test_size=0.2, random_state=42)


model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)


# Making predictions on the test set
y_pred = model.predict(X_test)

r2 = r2_score(y_test, y_pred)
print(f"R2-score {r2}")

mse = mean_squared_error(y_test, y_pred)
rmse = mse**0.5
print(f"Root Mean Squared Error (RMSE): {rmse}")








linear_model = LinearRegression()
linear_model.fit(X_train, y_train)


# Making predictions on the test set
y_pred = linear_model.predict(X_test)

r2 = r2_score(y_test, y_pred)
print(f"R2-score {r2}")

mse = mean_squared_error(y_test, y_pred)
rmse = mse**0.5
print(f"Root Mean Squared Error (RMSE): {rmse}")





from sklearn.tree import DecisionTreeRegressor

decision_model = DecisionTreeRegressor(random_state=42)
decision_model.fit(X_train, y_train)


# Making predictions on the test set
y_pred = decision_model.predict(X_test)

r2 = r2_score(y_test, y_pred)
print(f"R2-score {r2}")

mse = mean_squared_error(y_test, y_pred)
rmse = mse**0.5
print(f"Root Mean Squared Error (RMSE): {rmse}")





























import joblib

joblib.dump(model, './models/RFR_Model')





def load_model():
    global model
    model = joblib.load('./models/RFR_Model')





import locale

def predict_house_price(X, Y, size, type, energy_class, city):
    # Applying label encoding to the new house data 
    new_house = pd.DataFrame([[X, Y, size, type, energy_class, city]], columns=features)
    for feature in features:
        if new_house[feature].dtype == 'object':
            new_house[feature] = label_encoders[feature].transform(new_house[feature])
            
    # Letting the model predict the price
    predicted_price = model.predict(new_house)
    locale.setlocale(locale.LC_ALL, 'da_DK.UTF-8')
    formatted_price = locale.currency(predicted_price[0], grouping=True)
    print(f"Predicted price for the house: {formatted_price}")


predict_house_price(56.034845, 12.591295, 68, 'Ejerlejlighed', 'D', 3000)
